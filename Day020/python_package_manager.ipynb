{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Day 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m39.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.5/162.5 kB\u001b[0m \u001b[31m144.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m888.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m285.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m669.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2023.11.17 charset-normalizer-3.3.2 idna-3.6 requests-2.31.0 urllib3-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lia', 23), ('a', 17), ('li', 14), ('meta', 13), ('div', 13), ('ul', 10), ('input', 9), ('link', 7), ('gutenberg', 5), ('of', 5)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "\n",
    "responses = requests.get(url)\n",
    "text = responses.text\n",
    "cleaned_text = re.sub(r'[^\\w\\s]', '', text)  #To Remove punctuation\n",
    "words = cleaned_text.lower().split() \n",
    "word_counts = Counter(words)\n",
    "top_10_words = word_counts.most_common(10)\n",
    "print(top_10_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 - 5', '3 - 5', '3 - 7', '2 - 5', '4 - 7']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "response = requests.get(cats_api)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    cat_breeds = response.json()\n",
    "else:\n",
    "    print(\"Failed to retrieve information from API\")\n",
    "\n",
    "'''getting the list of the weights of all the cats in metric units, \n",
    "has upper and lower limits'''\n",
    "cat_weight_metric = []\n",
    "for i in range(len(cat_breeds)):\n",
    "  cat_weight_metric.append(cat_breeds[i]['weight']['metric'])\n",
    "cat_weight_metric[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14 - 15', '9 - 12', '11 - 15', '12 - 16', '15 - 17']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_weight= []\n",
    "for i in range(len(cat_breeds)):\n",
    "  cat_weight.append(cat_breeds[i]['life_span'])\n",
    "cat_weight[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max of upper limit cat's weights in metric units is: 11 \n",
      "Min of upper limit cat's weights in metric units is: 4 \n",
      "Mean of upper limit cat's weights in metric units is: 6.1940298507462686 \n",
      "Median of upper limit cat's weights in metric units is: 6 \n",
      "Std of upper limit cat's weights in metric units is: 1.416769757070632 \n",
      "{'Maximum': 11, 'Minimum': 4, 'Mean': 6.1940298507462686, 'Median': 6, 'standard diviation': 1.416769757070632}\n",
      "Upper limit of cat weights in metric units: {'Maximum': 11, 'Minimum': 4, 'Mean': 6.1940298507462686, 'Median': 6, 'standard diviation': 1.416769757070632}, lower limit of cat weights in metric units: {'Maximum': 5, 'Minimum': 2, 'Mean': 3.2238805970149254, 'Median': 3, 'standard diviation': 0.8845628182703051},upper limit of cat lifespan in years : {'Maximum': 20, 'Minimum': 12, 'Mean': 15.417910447761194, 'Median': 15, 'standard diviation': 1.6343774065406076},lower limits of cat lifespan in years: {'Maximum': 18, 'Minimum': 8, 'Mean': 12.074626865671641, 'Median': 12, 'standard diviation': 1.8283411328456127}\n",
      "Answer to first two sub questions of question 2: {'Upper limit stats of cat weights in metric units': {'Maximum': 11, 'Minimum': 4, 'Mean': 6.1940298507462686, 'Median': 6, 'standard diviation': 1.416769757070632}, 'Lower limit stats of cat weights in metric units': {'Maximum': 5, 'Minimum': 2, 'Mean': 3.2238805970149254, 'Median': 3, 'standard diviation': 0.8845628182703051}, 'Upper limit stat of cat lifespan in years': {'Maximum': 20, 'Minimum': 12, 'Mean': 15.417910447761194, 'Median': 15, 'standard diviation': 1.6343774065406076}, 'Lower limit stats of cat lifespan in years': {'Maximum': 18, 'Minimum': 8, 'Mean': 12.074626865671641, 'Median': 12, 'standard diviation': 1.8283411328456127}}\n",
      "defaultdict(<class 'int'>, {'Egypt': 3, 'Greece': 1, 'United States': 28, 'United Arab Emirates': 1, 'Australia': 1, 'France': 2, 'United Kingdom': 8, 'Burma': 2, 'Canada': 3, 'Cyprus': 1, 'Russia': 4, 'China': 1, 'Japan': 1, 'Thailand': 4, 'Isle of Man': 1, 'Norway': 1, 'Iran (Persia)': 1, 'Singapore': 1, 'Somalia': 1, 'Turkey': 2})\n"
     ]
    }
   ],
   "source": [
    "cat_weight= []\n",
    "for i in range(len(cat_breeds)):\n",
    "  cat_weight.append(cat_breeds[i]['life_span'])\n",
    "cat_weight[:5]\n",
    "# getting a function to make them integers and get two lists of upper and lower limits\n",
    "def convert_to_nums(string):\n",
    "    start, end = map(int, string.split(\" - \"))\n",
    "    return start, end\n",
    "# converting the weights to numbers using the function to get upper and lower weight limits for each, two lists:\n",
    "cat_weight_metric_number = list(map(convert_to_nums,cat_weight_metric))\n",
    "lower_cat_weight_metric,upper_cat_weight_metric = [i[0] for i in cat_weight_metric_number],[i[1]for i in cat_weight_metric_number]\n",
    "\n",
    "# same for lifespans in years\n",
    "cat_lifespan_number = list(map(convert_to_nums,cat_weight))\n",
    "lower_cat_lifespan,upper_cat_lifespan = [i[0] for i in cat_lifespan_number],[i[1]for i in cat_lifespan_number]\n",
    "\n",
    "import statistics as stats\n",
    "print(f'Max of upper limit cat\\'s weights in metric units is: {max(upper_cat_weight_metric)} ')\n",
    "print(f'Min of upper limit cat\\'s weights in metric units is: {min(upper_cat_weight_metric)} ')\n",
    "print(f'Mean of upper limit cat\\'s weights in metric units is: {stats.mean(upper_cat_weight_metric)} ')\n",
    "print(f'Median of upper limit cat\\'s weights in metric units is: {stats.median(upper_cat_weight_metric)} ')\n",
    "print(f'Std of upper limit cat\\'s weights in metric units is: {stats.stdev(upper_cat_weight_metric)} ')\n",
    "\n",
    "# Will use the function below to get the parameters\n",
    "def stats_paras(list):\n",
    "    \n",
    "    #Takes a list and returns a dictionary of certain statistics parameters of the list\n",
    "\n",
    "    import statistics as stats\n",
    "    stat_num = {}\n",
    "    stat_num['Maximum'] = max(list)\n",
    "    stat_num['Minimum'] = min(list)\n",
    "    stat_num['Mean'] = stats.mean(list)\n",
    "    stat_num['Median'] = stats.median(list)\n",
    "    stat_num['standard diviation'] = stats.stdev(list)\n",
    "    return stat_num\n",
    "print(stats_paras(upper_cat_weight_metric))\n",
    "\n",
    "\n",
    "\n",
    "print(f'Upper limit of cat weights in metric units: {stats_paras(upper_cat_weight_metric)}, lower limit of cat weights in metric units: {stats_paras(lower_cat_weight_metric)},upper limit of cat lifespan in years : {stats_paras(upper_cat_lifespan)},lower limits of cat lifespan in years: {stats_paras(lower_cat_lifespan)}')\n",
    "results = {}\n",
    "results['Upper limit stats of cat weights in metric units'] = stats_paras(upper_cat_weight_metric)\n",
    "results['Lower limit stats of cat weights in metric units'] = stats_paras(lower_cat_weight_metric)\n",
    "results['Upper limit stat of cat lifespan in years'] = stats_paras(upper_cat_lifespan)\n",
    "results['Lower limit stats of cat lifespan in years'] = stats_paras(lower_cat_lifespan)\n",
    "\n",
    "print(f'Answer to first two sub questions of question 2: {results}')\n",
    "\n",
    "\n",
    "# Third sub-question\n",
    "from collections import defaultdict\n",
    "# Getting the frequency table \n",
    "frequency_tables = defaultdict(int)\n",
    "cat_breed_info = {}\n",
    "for breed in cat_breeds:\n",
    "    cat_breed_info[breed['name']] = breed['origin']\n",
    "for breed in cat_breed_info.values():\n",
    "    frequency_tables[breed] += 1\n",
    "\n",
    "print(frequency_tables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m213.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=79235d2d3acdda8fef5162e53b65c429e89f24e64219abe1bb185345c960ad86\n",
      "  Stored in directory: /home/halima/.cache/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.12.2 bs4-0.0.1 soupsieve-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch the content. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the UCI Machine Learning Repository\n",
    "url = \"https://archive.ics.uci.edu/ml/datasets.php\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find the main content section\n",
    "    content = soup.find(\"body\")\n",
    "    \n",
    "    # Print the extracted content (you can modify this part)\n",
    "    print(content.get_text())\n",
    "else:\n",
    "    print(\"Failed to fetch the content. Status code:\", response.status_code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArewaDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
